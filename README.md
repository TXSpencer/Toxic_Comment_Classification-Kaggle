Toxic Comment Classification

Automated assessment of user-generated text, such as identifying toxic comments, serves as a crucial tool for managing the vast volume of online content. 
Regrettably, previous studies have revealed that these classifiers for toxicity often inherit biases from their training data.

The challenge is cast as a subpopulation shift problem. where distinct demographic identities represent these subpopulations. 
Our aim is to achieve high performance across all these subpopulations, rather than only focusing on the average performance across them. 
The emphasis is on reducing biases related to comments referencing specific demographic groups, rather than comments authored by individuals from those particular demographics.
